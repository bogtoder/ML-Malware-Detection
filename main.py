from sklearn.preprocessing import StandardScaler

import control_flow_graph_utils
import data_source
import input_file_manipulation
import feature_manipulation
import model_data_manipulation_utils
import model_utils


def test_control_flow_graph_with_first_file():
    one_file = input_file_manipulation.get_n_files_complete_data(1)[0]
    control_flow_graph = feature_manipulation.get_control_graph_features(one_file)

    print(control_flow_graph)
    control_flow_graph_utils.display_graph(control_flow_graph)


def test_ngrams_with_first_file():
    one_file = input_file_manipulation.get_n_files_complete_data(1)[0]
    ngrams = feature_manipulation.get_ngrams_features(one_file)

    print(ngrams)


def test_byte_histogram_with_first_file():
    one_file = input_file_manipulation.get_n_files_complete_data(1)[0]
    histograms = feature_manipulation.get_byte_histogram_features(one_file)

    return histograms


def test_model_byte_histogram(number_of_files_to_use=5000):

    X_data, y_data = feature_manipulation.get_features_for_n_random_files(number_of_files_to_use)

    scaler = StandardScaler()
    X_data = scaler.fit_transform(X_data)

    y_data = model_data_manipulation_utils.get_onehot_encoded_labels(y_data, data_source.num_malware_types)
    X_train, X_test, y_train, y_test = model_data_manipulation_utils.get_train_validation_split(X_data, y_data)

    model_utils.train_model(X_train, y_train)

    y_predictions = model_utils.get_predictions(X_test)

    model_utils.evaluate_neural_network(X_test, y_test, y_predictions)

    # print(f"Training accuracy: {model_utils.score_model(X_train, y_train)}")
    # print(f"Test accuracy: {model_utils.score_model(X_test, y_test)}")


# num_files_to_use = int(input(f"Enter number of files to use in this run (out of {data_source.num_files}): "))
num_files_to_use = 1000
test_model_byte_histogram(num_files_to_use)
