import numpy as np
from sklearn.preprocessing import StandardScaler

import control_flow_graph_utils
import data_source
import input_file_manipulation
import feature_manipulation
import model_data_manipulation_utils
import model_utils


def test_control_flow_graph_with_first_file():
    one_file = input_file_manipulation.get_n_files_complete_data(1)[0]
    control_flow_graph = feature_manipulation.get_control_graph_features(one_file)

    print(control_flow_graph)
    control_flow_graph_utils.display_graph(control_flow_graph)


def test_ngrams_with_first_file():
    one_file = input_file_manipulation.get_n_files_complete_data(1)[0]
    ngrams = feature_manipulation.get_ngrams_features(one_file)

    print(ngrams)


def test_byte_histogram_with_first_file():
    one_file = input_file_manipulation.get_n_files_complete_data(1)[0]
    histograms = feature_manipulation.get_byte_histogram_features(one_file)

    return histograms


def test_model_byte_histogram(number_of_files_to_use=5000):

    X_data, y_data = feature_manipulation.get_features_for_n_random_files(number_of_files_to_use, use_existing_features=True)

    scaler = StandardScaler()
    X_data = scaler.fit_transform(X_data)

    y_data = model_data_manipulation_utils.get_onehot_encoded_labels(y_data, data_source.num_malware_types)
    X_train, X_test, y_train, y_test = model_data_manipulation_utils.get_train_validation_split(X_data, y_data)

    training_history = model_utils.train_model(X_train, y_train)

    y_predictions = model_utils.get_predictions(X_test)

    model_utils.evaluate_neural_network(X_test, y_test, y_predictions)

    model_utils.save_model_onnx_format()


def test_model_byte_freqs_and_entropy(number_of_files_to_use=100):

    X_data, y_data = feature_manipulation.get_features_for_n_random_files(number_of_files_to_use, use_existing_features=True)

    X_data = np.array(X_data)

    y_data = model_data_manipulation_utils.get_onehot_encoded_labels(y_data, data_source.num_malware_types)
    X_train, X_test, y_train, y_test = model_data_manipulation_utils.get_train_validation_split(X_data, y_data)

    model_utils.train_model(X_train, y_train)

    y_predictions = model_utils.get_predictions(X_test)

    model_utils.evaluate_neural_network(X_test, y_test, y_predictions)

    # model_utils.save_model_onnx_format()


def compare_models_for_bytefreqs(number_of_files_to_use=1000):
    X_data, y_data = feature_manipulation.get_features_for_n_random_files(number_of_files_to_use, use_existing_features=True)

    X_data = np.array(X_data)

    y_data = model_data_manipulation_utils.get_onehot_encoded_labels(y_data, data_source.num_malware_types)
    X_train, X_test, y_train, y_test = model_data_manipulation_utils.get_train_validation_split(X_data, y_data)

    model_utils.evaluate_models(X_train, y_train, X_test, y_test)


def display_labels_distribution():
    feature_manipulation.display_label_distribution()


# num_files_to_use = 5000
# test_model_byte_freqs_and_entropy(num_files_to_use)
# compare_models_for_bytefreqs(num_files_to_use)

display_labels_distribution()
