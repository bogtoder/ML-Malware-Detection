import datetime
import os.path

import onnx
import tensorflow as tf
import numpy as np
import tf2onnx.tfonnx
from matplotlib import pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, recall_score, precision_score, f1_score
from tensorflow.python.keras.layers import Dense, Dropout
from tensorflow.python.keras.metrics import Recall, Precision
from tensorflow.python.keras.models import Sequential


def get_RandomForestClassifier_model():
    return RandomForestClassifier(n_estimators=100)


def get_feedforward_neuralnetwork_model_bytehistograms():
    model = Sequential()
    model.add(Dense(128, input_dim=256, activation='relu'))  # input_dim matches the length of the feature vectors
    model.add(Dense(64, activation='relu'))
    model.add(Dense(10, activation='softmax'))  # 10 classes of malware

    # Compile the model
    model.compile(loss='categorical_crossentropy',  # use categorical_crossentropy for multi-class classification
                  optimizer='adam',
                  metrics=['accuracy', Recall(name='custom_recall'), Precision(name='custom_precision')])

    return model


def get_feedforward_neuralnetwork_model_bytefreqs_v1():
    model = Sequential()
    model.add(Dense(256, input_dim=257, activation='relu'))  # input_dim matches the length of the feature vectors
    model.add(Dense(128, activation='relu'))
    model.add(Dense(128, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(10, activation='softmax'))  # 10 classes of malware

    # Compile the model
    model.compile(loss='categorical_crossentropy',  # use categorical_crossentropy for multi-class classification
                  optimizer='adam',
                  metrics=['accuracy', Recall(name='custom_recall'), Precision(name='custom_precision')])

    return model


def get_feedforward_neuralnetwork_model_bytefreqs_v2():
    model = Sequential()
    model.add(Dense(128, input_dim=257, activation='relu'))  # same as v1 but reduced size
    model.add(Dense(64, activation='relu'))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(10, activation='softmax'))

    # Compile the model
    model.compile(loss='categorical_crossentropy',  # use categorical_crossentropy for multi-class classification
                  optimizer='adam',
                  metrics=['accuracy', Recall(name='custom_recall'), Precision(name='custom_precision')])

    return model


def get_feedforward_neuralnetwork_model_bytefreqs_v3():
    model = Sequential()
    model.add(Dense(256, input_dim=257, activation='relu'))  # same as v1 but using Dropout to counter overfitting
    model.add(Dropout(0.5))
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(10, activation='softmax'))

    # Compile the model
    model.compile(loss='categorical_crossentropy',  # use categorical_crossentropy for multi-class classification
                  optimizer='adam',
                  metrics=['accuracy', Recall(name='custom_recall'), Precision(name='custom_precision')])

    return model


# _model_object_ = get_feedforward_neuralnetwork_model()  # model for raw byte histograms
_model_object_ = get_feedforward_neuralnetwork_model_bytefreqs_v3()  # model for byte frequencies and entropy
_model_history_ = None

################# DEFINE MODEL ARCHITECTURES ABOVE THIS LINE ###################
################# MANIPULATE MODEL BELOW #################


def get_model():
    return _model_object_


def train_model(train_features, train_labels):
    # train_labels should already be onehot_encoded at this point if using a neural network
    # shape = train_features.shape
    batch_size = 32

    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)

    print("Started training model...")
    history = _model_object_.fit(train_features, train_labels, epochs=100, batch_size=batch_size, callbacks=[callback])
    print("Done training model.")

    return history


def get_predictions(X_test):
    return _model_object_.predict(X_test)


def score_model(X, y):
    return _model_object_.score(X, y)


def evaluate_neural_network(X_test, y_test, y_predictions):
    # test_loss, test_accuracy, test_recall = _model_object_.evaluate(X_test, y_test)
    # print(f"Test accuracy: {test_accuracy}")
    # print(f"Test recall: {test_recall}")

    predicted_classes = np.argmax(y_predictions, axis=1)
    true_labels = np.argmax(y_test, axis=1)

    print(classification_report(true_labels, predicted_classes))

    evaluate_binary_metrics(true_labels, predicted_classes)


def evaluate_binary_metrics(y_true, y_pred):
    """
    Calculate Recall and Precision for binary classification by converting multi-class labels.

    Parameters:
    - y_true: True labels (list or array)
    - y_pred: Predicted labels from the model (list or array)

    Returns:
    - recall: Recall score for binary classification
    - precision: Precision score for binary classification
    """

    # Convert multi-class labels to binary
    y_true_binary = [0 if label == 9 else 1 for label in y_true]
    y_pred_binary = [0 if label == 9 else 1 for label in y_pred]

    # Calculate Recall and Precision
    recall = recall_score(y_true_binary, y_pred_binary)
    precision = precision_score(y_true_binary, y_pred_binary)
    f1 = f1_score(y_true_binary, y_pred_binary)

    print('Metrics for the binary classification are:')
    print(f'\tRecall: {recall}')
    print(f'\tPrecision: {precision}')
    print(f'\tF1: {f1}')

    return recall, precision, f1


def save_model_onnx_format(model_to_save=_model_object_):
    save_path = "saved_models/model_bytefreqs_and_entropy_modelv3_samples8000_plus_benign"

    model_proto, _ = tf2onnx.convert.from_keras(model_to_save)

    with open(os.path.join(save_path, "model.onnx"), "wb") as f:
        f.write(model_proto.SerializeToString())

    test_load = onnx.load(os.path.join(save_path, "model.onnx"))
    onnx.checker.check_model(test_load)


def evaluate_models(X_train, y_train, X_test, y_test):
    model_original = get_feedforward_neuralnetwork_model_bytefreqs_v1()
    history_original = model_original.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, verbose=0)

    model_reduced = get_feedforward_neuralnetwork_model_bytefreqs_v2()
    history_reduced = model_reduced.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, verbose=0)

    model_dropout = get_feedforward_neuralnetwork_model_bytefreqs_v3()
    history_dropout = model_dropout.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, verbose=0)

    plt.figure(figsize=(20, 10))

    plt.suptitle(f"Results for {len(X_train) + len(X_test)} files with 20% train/validation split")

    # Accuracy
    plt.subplot(2, 2, 1)
    plt.plot(history_original.history['accuracy'], label='V1_Train', color='blue')
    plt.plot(history_original.history['val_accuracy'], label='V1_Validation', color='blue', linestyle='dashed')
    plt.plot(history_reduced.history['accuracy'], label='V2_Train', color='green')
    plt.plot(history_reduced.history['val_accuracy'], label='V2_Validation', color='green', linestyle='dashed')
    plt.plot(history_dropout.history['accuracy'], label='V3_Train', color='red')
    plt.plot(history_dropout.history['val_accuracy'], label='V3_Validation', color='red', linestyle='dashed')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    # Loss
    plt.subplot(2, 2, 2)
    plt.plot(history_original.history['loss'], label='V1_Train', color='blue')
    plt.plot(history_original.history['val_loss'], label='V1_Validation', color='blue', linestyle='dashed')
    plt.plot(history_reduced.history['loss'], label='V2_Train', color='green')
    plt.plot(history_reduced.history['val_loss'], label='V2_Validation', color='green', linestyle='dashed')
    plt.plot(history_dropout.history['loss'], label='V3_Train', color='red')
    plt.plot(history_dropout.history['val_loss'], label='V3_Validation', color='red', linestyle='dashed')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    # Recall
    plt.subplot(2, 2, 3)
    plt.plot(history_original.history['custom_recall'], label='V1_Train', color='blue')
    plt.plot(history_original.history['val_custom_recall'], label='V1_Validation', color='blue', linestyle='dashed')
    plt.plot(history_reduced.history['custom_recall'], label='V2_Train', color='green')
    plt.plot(history_reduced.history['val_custom_recall'], label='V2_Validation', color='green', linestyle='dashed')
    plt.plot(history_dropout.history['custom_recall'], label='V3_Train', color='red')
    plt.plot(history_dropout.history['val_custom_recall'], label='V3_Validation', color='red', linestyle='dashed')
    plt.xlabel('Epochs')
    plt.ylabel('Recall')
    plt.legend()

    # F1 Score
    f1_original = [2 * (p * r) / (p + r) if (p + r) != 0 else 0 for p, r in
                   zip(history_original.history['custom_precision'], history_original.history['custom_recall'])]
    val_f1_original = [2 * (p * r) / (p + r) if (p + r) != 0 else 0 for p, r in
                       zip(history_original.history['val_custom_precision'], history_original.history['val_custom_recall'])]
    f1_reduced = [2 * (p * r) / (p + r) if (p + r) != 0 else 0 for p, r in
                  zip(history_reduced.history['custom_precision'], history_reduced.history['custom_recall'])]
    val_f1_reduced = [2 * (p * r) / (p + r) if (p + r) != 0 else 0 for p, r in
                      zip(history_reduced.history['val_custom_precision'], history_reduced.history['val_custom_recall'])]
    f1_dropout = [2 * (p * r) / (p + r) if (p + r) != 0 else 0 for p, r in
                  zip(history_dropout.history['custom_precision'], history_dropout.history['custom_recall'])]
    val_f1_dropout = [2 * (p * r) / (p + r) if (p + r) != 0 else 0 for p, r in
                      zip(history_dropout.history['val_custom_precision'], history_dropout.history['val_custom_recall'])]

    plt.subplot(2, 2, 4)
    plt.plot(f1_original, label='V1_Train', color='blue')
    plt.plot(val_f1_original, label='V1_Validation', color='blue', linestyle='dashed')
    plt.plot(f1_reduced, label='V2_Train', color='green')
    plt.plot(val_f1_reduced, label='V2_Validation', color='green', linestyle='dashed')
    plt.plot(f1_dropout, label='V3_Train', color='red')
    plt.plot(val_f1_dropout, label='V3_Validation', color='red', linestyle='dashed')
    plt.xlabel('Epochs')
    plt.ylabel('F1 Score')
    plt.legend()

    plt.tight_layout()
    plt.show()

    save_model_onnx_format(model_dropout)
